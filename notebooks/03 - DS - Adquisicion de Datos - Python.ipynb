{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/efviodo/idatha-data-science-course/blob/master/notebooks/03%20-%20DS%20-%20Adquisicion%20de%20Datos%20-%20Python.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/efviodo/idatha-data-science-course/raw/master/notebooks/figures/idatha-logo.jpeg\" width=\"100px\" height=\"100px\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adquisición de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "- Entender que es la etapa de adquisición de datos\n",
    "- Familiarizarse con las fuentes de datos más comunes\n",
    "- Introducir algunas facilidades en Python para adquisición de datos\n",
    "- Enumerar los principales desafíos y riesgos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Indice'></a>\n",
    "## Índice\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "1. [¿Qué es la adquisición de datos?](#Adquisicion-Datos)\n",
    "1. [Fuentes de Datos](#Fuentes-Datos)\n",
    "    1. [Definición](#Definicion)\n",
    "    1. [Tipos](#Tipos)\n",
    "1. [Herramientas](#Herramientas)\n",
    "    1. [Bases de Datos (BDs)](#Bases-Datos)\n",
    "    1. [Sitios Web](#Sitios-Web)\n",
    "    1. [Datos Abiertos](#Datos-Abiertos)\n",
    "    1. [APIs REST](#Rest-Apis)\n",
    "1. [Fuentes de Datos Abiertas](#Fuentes-Datos-Abiertas)\n",
    "1. [Desafíos](#Desafios)\n",
    "1. [Bibliografía](#Bibliografia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Adquisicion-Datos'></a>\n",
    "## ¿Qué es la adquisición de datos?\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "La adquisición de datos o también conocido como ingesta de datos, es el proceso de obtener o importar los datos\n",
    "que se pretenden analizar, desde su **fuente**, y almacenarlos temporal o permanentemente para su posterior análisis.\n",
    "\n",
    "Como resultado de esta operación, el científico de datos tiene a su dispocición uno o varios set de datos en un formato comprendido y manejado por este (archivos CSV, resultado de consultas SQL, data frames, etc), listo para comenzar con el análisis y el entendimiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Fuentes-Datos'></a>\n",
    "## Fuentes de Datos\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "<a id='Definicion'></a>\n",
    "### Definición\n",
    "La fuente de un dato, es el lugar donde se encuentra el dato, desde la perspectiva de quien diseña el proceso de análisis. Por ejemplo, puede ser un sensor IoT (Internet de las Cosas) al cual puedo conectarme para leer información, Redes Sociales (Twtter, Facebook), un sistema [ERP](https://es.wikipedia.org/wiki/Sistema_de_planificaci%C3%B3n_de_recursos_empresariales), base de datos de un cliente, sistemas de almacenamiento legados, fuentes de datos abiertas, sitios web, etc.\n",
    "\n",
    "Cada vez son más y más los lugares donde se originan datos y a los cuales podemos acceder y explotar. Conforme crecen las fuentes de datos, también crecen y se originan nuevas tecnologías para acceder a ellos.\n",
    "\n",
    "### Tipos\n",
    "Dependiendo de donde se encuentren los datos, como accederemos a ellos, es decir como nos conectamos y que tecnología utilizamos. De esta forma, resulta útil agrupar las fuentes de datos en diferentes tipos:\n",
    "\n",
    "- Bases de datos de clientes: Relacionales/No Relacionales, archivos PDF, fotos (PNG, JPG...), Big Data, etc.\n",
    "- Sitios Web: Técnicas de web crawling y web scraping\n",
    "- Redes sociales: Integración via APIs REST\n",
    "- Datos Abiertos: Carga de archivos con formato (CSV, TXT, PDF, etc), integración mediante APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Herramientas'></a>\n",
    "## Herramientas\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "Cada lenguaje de programación tiene su oferta de herramientas que facilitan la integración con otros sistemas, y así la adquisición de datos. A continuación se enumeran algunos ejemplos de herramientas que podrás encontrar en **Python**, y que te ayudaran en la adiquisición de datos. \n",
    "\n",
    "<a id='Bases-Datos'></a>\n",
    "### Bases de Datos (BDs)\n",
    "Dentro de **Python**, podemos encontrar variedad de librerias para acceder a distintos motores de base de datos, MySQL, Oracle, PostgreSQL, MongoDB, etc. Algunos ejemplos de librerías para conectarse a bases de datos:\n",
    "\n",
    "* MongoDB &rarr; [PyMongo](https://pypi.org/project/pymongo/)\n",
    "* PostgreSQL &rarr; [Psycopg2](https://pypi.org/project/psycopg2/)\n",
    "* MySQL &rarr; [mysql-connector](https://www.w3schools.com/python/python_mysql_getstarted.asp)\n",
    "\n",
    "<a id='Sitios-Web'></a>\n",
    "### Sitios Web\n",
    "\n",
    "Es bastante común, la necesidad de extraer información de un sitio web y de a su vez de forma automática. Para ello existen dos técnicas bien conocidas que son: (i) Web Scarping y (ii) Web Crawling.\n",
    "\n",
    "#### ¿Qué es web Scraping?\n",
    "Es el acto de procesar un documento web y extraer información del mismo. \n",
    "\n",
    "#### ¿Qué es web Crawling?\n",
    "Es el proceso de encontrar y recuperar \"web links\", desde una lista inicial de URLs, navegando el contenido de la lista inicial y aplicando técnicas de web scraping para encontrar nuevos links.\n",
    "\n",
    "Existen varias herramientas que implementan estas técnicas, una de las más populares es la libreria de Python [Scrapy](https://scrapy.org/).\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "A continuación vamos a ver un ejemplo de como extraer información del popular sitio web de reseñas de peliculas, [IMDb](https://www.imdb.com). Para ello vamos a usar **Python** y las librerias [Requests](https://pypi.org/project/requests/) y [BeautifulSoup](https://pypi.org/project/beautifulsoup4/), para recuperar los primeros resultados de búsqueda de peliculas cuya fecha de lanzamiento se encuentra entre el año 2018 y 2019.\n",
    "\n",
    "Si te sientes curioso, hacer el scrapping completo de un sitio web puede ser bastante más complicado que esto, incluso si queremos navegar en paginas hijas y descargar un sitio completo. Para ello suelen utilizarse librerías más elaboradas como [Scrapy](https://docs.scrapy.org/en/latest/intro/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (2019.3.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (1.24.3)\n",
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 2.8MB/s a 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>=1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/42/d821581cf568e9b7dfc5b415aa61952b0f5e3dede4f3cbd650e3a1082992/soupsieve-1.9.4-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/emiliano/.cache/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.8.0 bs4-0.0.1 soupsieve-1.9.4\n"
     ]
    }
   ],
   "source": [
    "# Instalacion de librerias\n",
    "!pip install requests\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joker\n",
      "Ad Astra\n",
      "Rambo: Last Blood\n",
      "Downton Abbey\n",
      "Hustlers\n",
      "It Chapter Two\n",
      "Midsommar\n",
      "The Irishman\n",
      "Doom: Annihilation\n",
      "El Camino: A Breaking Bad Movie\n",
      "Once Upon a Time... in Hollywood\n",
      "Between Two Ferns: The Movie\n",
      "Spider-Man: Far from Home\n",
      "Fast & Furious Presents: Hobbs & Shaw\n",
      "Tall Girl\n",
      "Crawl\n",
      "Judy\n",
      "Aladdin\n",
      "In the Shadow of the Moon\n",
      "Anna\n",
      "Avengers: Endgame\n",
      "Uncut Gems\n",
      "Frozen II\n",
      "Dark Phoenix\n",
      "Star Wars: The Rise of Skywalker\n",
      "Yesterday\n",
      "John Wick: Chapter 3 - Parabellum\n",
      "Toy Story 4\n",
      "Three from Hell\n",
      "Abominable\n",
      "The Goldfinch\n",
      "Zombieland: Double Tap\n",
      "Ready or Not\n",
      "Terminator: Dark Fate\n",
      "Bohemian Rhapsody\n",
      "Running with the Devil\n",
      "Gemini Man\n",
      "Bloodline\n",
      "Rocketman\n",
      "Child's Play\n",
      "Gisaengchung\n",
      "Angel Has Fallen\n",
      "The Peanut Butter Falcon\n",
      "Annabelle Comes Home\n",
      "Maleficent: Mistress of Evil\n",
      "Charlie's Angels\n",
      "War\n",
      "The Lion King\n",
      "Knives Out\n",
      "Good Boys\n",
      "Men in Black: International\n",
      "Kabir Singh\n",
      "The Dead Don't Die\n",
      "Booksmart\n",
      "Godzilla: King of the Monsters\n",
      "The Lighthouse\n",
      "Haunt\n",
      "Alita: Battle Angel\n",
      "Ford v Ferrari\n",
      "Aquaman\n",
      "Robin Hood\n",
      "Inside Man: Most Wanted\n",
      "The Day Shall Come\n",
      "The Addams Family\n",
      "Doctor Sleep\n",
      "Lucy in the Sky\n",
      "Jojo Rabbit\n",
      "Hereditary\n",
      "Hotel Mumbai\n",
      "We Have Always Lived in the Castle\n",
      "Spider-Man: Into the Spider-Verse\n",
      "Scary Stories to Tell in the Dark\n",
      "The Aeronauts\n",
      "Brightburn\n",
      "Danger Close: The Battle of Long Tan\n",
      "Can You Keep a Secret?\n",
      "Dream Girl\n",
      "Welcome to Marwen\n",
      "Long Shot\n",
      "Shazam!\n",
      "Animales fantásticos: Los crímenes de Grindelwald\n",
      "Jay and Silent Bob Reboot\n",
      "Last Christmas\n",
      "Avengers: Infinity War\n",
      "The Lego Movie 2: The Second Part\n",
      "Us\n",
      "Jumanji: The Next Level\n",
      "A Simple Favor\n",
      "Midway\n",
      "Green Book\n",
      "Wounds\n",
      "Captain Marvel\n",
      "The Secret Life of Pets 2\n",
      "The Laundromat\n",
      "Dora and the Lost City of Gold\n",
      "The Hustle\n",
      "Chhichhore\n",
      "Corporate Animals\n",
      "Mary Queen of Scots\n",
      "Dolor y gloria\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define URL a descargar y hace la petición HTTP\n",
    "url = 'http://www.imdb.com/search/title?count=100&release_date=2018,2019&title_type=feature'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Crea objeto BeautifulSoup para procesar HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Obtengo todos los elementos H3 con clase de estilos lister-item-header (yo se que allí estan los títulos)\n",
    "elements = soup.findAll('h3', {'class': 'lister-item-header'})\n",
    "\n",
    "# El resultado es una lista, itero para cada uno\n",
    "for element in elements:\n",
    "    # El titulo está dentro de un link\n",
    "    title = element.find(\"a\", recursive=False).next\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar, la comlejidad que implica hacer web scarping para un data scientist\n",
    "- Necesitamos conocer la estructura de la página web.\n",
    "- Conocer las básicas de HTML, CSS, entre otros.\n",
    "- Si la estructura de la página cambia, necesito cambiar el programa que hace scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Datos-Abiertos'></a>\n",
    "### Datos abiertos\n",
    "Los datos abiertos suelen encontrarse en diferentes formatos, pero los principales son: CSV, XML, JSON, TXT y PDF. A su vez, dependiendo de la naturaleza del dato, puede que encuentres otros formatos como PNG (usualmente en datasets de imagenes en el área Computer Vision) o Shapefile (datos espaciales).\n",
    "\n",
    "Afortunadamente, existen librerias que implementan el acceso a estos formatos de archivos y manejan toda la complejidad de leerlos y extraer la información que necesitamos.\n",
    "\n",
    "Para fijar ideas, vamos a ver como descargar un archivo CSV de datos, cargarlo y recuperar un poco de información del mismo. Para ello vamos a usar nuevamente la libería [Requests](https://pypi.org/project/requests/) las librerias y además utilizaremos la librefía [Pandas](https://pandas.pydata.org/) para facilitar la carga de los datos como una tabla y manipularlos mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101220.0</td>\n",
       "      <td>101353.0</td>\n",
       "      <td>101453.0</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102053.0</td>\n",
       "      <td>102577.0</td>\n",
       "      <td>103187.0</td>\n",
       "      <td>103795.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>8996351.0</td>\n",
       "      <td>9166764.0</td>\n",
       "      <td>9345868.0</td>\n",
       "      <td>9533954.0</td>\n",
       "      <td>9731361.0</td>\n",
       "      <td>9938414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26616792.0</td>\n",
       "      <td>27294031.0</td>\n",
       "      <td>28004331.0</td>\n",
       "      <td>28803167.0</td>\n",
       "      <td>29708599.0</td>\n",
       "      <td>30696958.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>32758020.0</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>34656032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>5643182.0</td>\n",
       "      <td>5753024.0</td>\n",
       "      <td>5866061.0</td>\n",
       "      <td>5980417.0</td>\n",
       "      <td>6093321.0</td>\n",
       "      <td>6203299.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20997687.0</td>\n",
       "      <td>21759420.0</td>\n",
       "      <td>22549547.0</td>\n",
       "      <td>23369131.0</td>\n",
       "      <td>24218565.0</td>\n",
       "      <td>25096150.0</td>\n",
       "      <td>25998340.0</td>\n",
       "      <td>26920466.0</td>\n",
       "      <td>27859305.0</td>\n",
       "      <td>28813463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2970017.0</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82683.0</td>\n",
       "      <td>83861.0</td>\n",
       "      <td>84462.0</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83751.0</td>\n",
       "      <td>82431.0</td>\n",
       "      <td>80788.0</td>\n",
       "      <td>79223.0</td>\n",
       "      <td>78014.0</td>\n",
       "      <td>77281.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code     Indicator Name Indicator Code       1960  \\\n",
       "0        Aruba          ABW  Population, total    SP.POP.TOTL    54211.0   \n",
       "1  Afghanistan          AFG  Population, total    SP.POP.TOTL  8996351.0   \n",
       "2       Angola          AGO  Population, total    SP.POP.TOTL  5643182.0   \n",
       "3      Albania          ALB  Population, total    SP.POP.TOTL  1608800.0   \n",
       "4      Andorra          AND  Population, total    SP.POP.TOTL    13411.0   \n",
       "\n",
       "        1961       1962       1963       1964       1965  ...        2007  \\\n",
       "0    55438.0    56225.0    56695.0    57032.0    57360.0  ...    101220.0   \n",
       "1  9166764.0  9345868.0  9533954.0  9731361.0  9938414.0  ...  26616792.0   \n",
       "2  5753024.0  5866061.0  5980417.0  6093321.0  6203299.0  ...  20997687.0   \n",
       "3  1659800.0  1711319.0  1762621.0  1814135.0  1864791.0  ...   2970017.0   \n",
       "4    14375.0    15370.0    16412.0    17469.0    18549.0  ...     82683.0   \n",
       "\n",
       "         2008        2009        2010        2011        2012        2013  \\\n",
       "0    101353.0    101453.0    101669.0    102053.0    102577.0    103187.0   \n",
       "1  27294031.0  28004331.0  28803167.0  29708599.0  30696958.0  31731688.0   \n",
       "2  21759420.0  22549547.0  23369131.0  24218565.0  25096150.0  25998340.0   \n",
       "3   2947314.0   2927519.0   2913021.0   2905195.0   2900401.0   2895092.0   \n",
       "4     83861.0     84462.0     84449.0     83751.0     82431.0     80788.0   \n",
       "\n",
       "         2014        2015        2016  \n",
       "0    103795.0    104341.0    104822.0  \n",
       "1  32758020.0  33736494.0  34656032.0  \n",
       "2  26920466.0  27859305.0  28813463.0  \n",
       "3   2889104.0   2880703.0   2876101.0  \n",
       "4     79223.0     78014.0     77281.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://github.com/efviodo/idatha-data-science-course/raw/master/notebooks/datasets/world-bank-data/country_population.csv\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = requests.get(url).content\n",
    "\n",
    "df = pd.read_csv(io.StringIO(data.decode('utf-8')))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, acabamos de leer los datos de senso de población de diferentes países para distintos años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 61)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Puedo analizar las dimensiones del dataset como cantidad de columnas o filas de datos.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
       "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
       "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
       "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
       "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
       "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
       "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
       "       '2014', '2015', '2016'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver que columnas tiene nuestro data frame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>104822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>34656032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>28813463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2876101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>77281.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name        2016\n",
       "0        Aruba    104822.0\n",
       "1  Afghanistan  34656032.0\n",
       "2       Angola  28813463.0\n",
       "3      Albania   2876101.0\n",
       "4      Andorra     77281.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecciona solamente las columnas Nombre de Pais y población en el año 2016\n",
    "df2 = df[['Country Name', '2016']];\n",
    "\n",
    "# Ordena de forma ascendente (para ordenar de forma descendente usar desc())\n",
    "df2.sort_values(by=['2016'])\n",
    "\n",
    "# Obtiene primeros 5 resultados\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python tiene una gran variedad de librerías para trabajar con datos. En particulr la librería pandas es bastante utilizada por su uso eficiente de memoria y optimizaciones sobre matrices utilizando [numpy](https://numpy.org/) para operaciones. Más adelante en este taller vamos a ir viendo más ejemplos de operaciones y transformaciones utilizando Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Rest-Apis'></a>\n",
    "### APIs REST\n",
    "Muchas veces en un proyecto de ciencia de datos, tenemos el requerimiento de acceder a los datos a través de una API REST. Naturalmente no vamos a re-implementar la rueda y desarrollar un programa que establezca una conexión HTTP, parse la respuesta, etc. Existen librerias que implementan clientes rest y también librerías que nos ayudan a parsear respuestas en formato JSON, XML, etc. Veamos un ejemplo en el que utilizamos las librerias ```httr``` y ```jsonlite``` para invocar la API de la popular plataforma de compra venta de bienes y servicios [Mercado Libre](https://developers.mercadolibre.com.uy/es_ar). En el mismo, vamos a recuperar y mostrar información de las categorías de productos que se ofrecen a través de la plataforma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consumiendo servicio REST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importo librerias \n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Dirección del servicio en la API REST\n",
    "url = \"https://api.mercadolibre.com/sites/MLU\"\n",
    "\n",
    "# Invocación al método\n",
    "response = requests.get(url)\n",
    "\n",
    "# Obtenemos el status code de la respuesta con el operador '$'\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parseando contenido de la respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLU5725</td>\n",
       "      <td>Accesorios para Vehículos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLU1403</td>\n",
       "      <td>Alimentos y Bebidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLU1071</td>\n",
       "      <td>Animales y Mascotas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLU1367</td>\n",
       "      <td>Arte y Antigüedades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLU1743</td>\n",
       "      <td>Autos, Motos y Otros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       name\n",
       "0  MLU5725  Accesorios para Vehículos\n",
       "1  MLU1403        Alimentos y Bebidas\n",
       "2  MLU1071        Animales y Mascotas\n",
       "3  MLU1367        Arte y Antigüedades\n",
       "4  MLU1743       Autos, Motos y Otros"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraigo el contenido de la respuesta como JSON\n",
    "content = response.json()\n",
    "\n",
    "# El resultado tiene varios atributos, me quedo solo con el atributo categorias\n",
    "categories = content['categories']\n",
    "\n",
    "# Construyo un data frame a partir del la lista de categorias\n",
    "df = pd.DataFrame.from_dict(categories)\n",
    "\n",
    "# Veamos el resultado\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parseando como JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"MLU5725\",\n",
      "    \"name\": \"Accesorios para Veh\\u00edculos\",\n",
      "    \"picture\": \"http://resources.mlstatic.com/category/images/a0572646-bbf9-4b24-81c8-603723a015ba.png\",\n",
      "    \"permalink\": \"http://home.mercadolibre.com.uy/vehiculos-accesorios/\",\n",
      "    \"total_items_in_this_category\": 456475,\n",
      "    \"path_from_root\": [\n",
      "        {\n",
      "            \"id\": \"MLU5725\",\n",
      "            \"name\": \"Accesorios para Veh\\u00edculos\"\n",
      "        }\n",
      "    ],\n",
      "    \"children_categories\": [\n",
      "        {\n",
      "            \"id\": \"MLU417044\",\n",
      "            \"name\": \"Acc. y Repuestos N\\u00e1uticos\",\n",
      "            \"total_items_in_this_category\": 68\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1747\",\n",
      "            \"name\": \"Accesorios Autos y Camionetas\",\n",
      "            \"total_items_in_this_category\": 70470\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1772\",\n",
      "            \"name\": \"Accesorios para Motos\",\n",
      "            \"total_items_in_this_category\": 23218\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1023\",\n",
      "            \"name\": \"Audio para Autos\",\n",
      "            \"total_items_in_this_category\": 11543\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU208681\",\n",
      "            \"name\": \"Llantas\",\n",
      "            \"total_items_in_this_category\": 4843\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU208675\",\n",
      "            \"name\": \"Neum\\u00e1ticos\",\n",
      "            \"total_items_in_this_category\": 15859\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1748\",\n",
      "            \"name\": \"Repuestos Autos y Camionetas\",\n",
      "            \"total_items_in_this_category\": 270442\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1771\",\n",
      "            \"name\": \"Repuestos para Motos\",\n",
      "            \"total_items_in_this_category\": 29976\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU206455\",\n",
      "            \"name\": \"Service Programado\",\n",
      "            \"total_items_in_this_category\": 2527\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU5679\",\n",
      "            \"name\": \"Tuning\",\n",
      "            \"total_items_in_this_category\": 20745\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU6177\",\n",
      "            \"name\": \"Otros\",\n",
      "            \"total_items_in_this_category\": 6795\n",
      "        }\n",
      "    ],\n",
      "    \"attribute_types\": \"none\",\n",
      "    \"settings\": {\n",
      "        \"adult_content\": false,\n",
      "        \"buying_allowed\": true,\n",
      "        \"buying_modes\": [\n",
      "            \"buy_it_now\",\n",
      "            \"auction\"\n",
      "        ],\n",
      "        \"catalog_domain\": null,\n",
      "        \"coverage_areas\": \"not_allowed\",\n",
      "        \"currencies\": [\n",
      "            \"UYU\",\n",
      "            \"USD\"\n",
      "        ],\n",
      "        \"fragile\": false,\n",
      "        \"immediate_payment\": \"optional\",\n",
      "        \"item_conditions\": [\n",
      "            \"used\",\n",
      "            \"not_specified\",\n",
      "            \"new\"\n",
      "        ],\n",
      "        \"items_reviews_allowed\": false,\n",
      "        \"listing_allowed\": false,\n",
      "        \"max_description_length\": 50000,\n",
      "        \"max_pictures_per_item\": 12,\n",
      "        \"max_pictures_per_item_var\": 10,\n",
      "        \"max_sub_title_length\": 70,\n",
      "        \"max_title_length\": 60,\n",
      "        \"maximum_price\": null,\n",
      "        \"minimum_price\": null,\n",
      "        \"mirror_category\": null,\n",
      "        \"mirror_master_category\": null,\n",
      "        \"mirror_slave_categories\": [],\n",
      "        \"price\": \"required\",\n",
      "        \"reservation_allowed\": \"not_allowed\",\n",
      "        \"restrictions\": [],\n",
      "        \"rounded_address\": false,\n",
      "        \"seller_contact\": \"not_allowed\",\n",
      "        \"shipping_modes\": [\n",
      "            \"not_specified\",\n",
      "            \"custom\"\n",
      "        ],\n",
      "        \"shipping_options\": [\n",
      "            \"carrier\",\n",
      "            \"custom\"\n",
      "        ],\n",
      "        \"shipping_profile\": \"optional\",\n",
      "        \"show_contact_information\": false,\n",
      "        \"simple_shipping\": \"optional\",\n",
      "        \"stock\": \"required\",\n",
      "        \"sub_vertical\": null,\n",
      "        \"subscribable\": false,\n",
      "        \"tags\": [],\n",
      "        \"vertical\": null,\n",
      "        \"vip_subdomain\": \"articulo\",\n",
      "        \"buyer_protection_programs\": [\n",
      "            \"delivered\",\n",
      "            \"undelivered\"\n",
      "        ]\n",
      "    },\n",
      "    \"meta_categ_id\": null,\n",
      "    \"attributable\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Obtengo el identificador de la categoria en el resultado, para ello selecciona la primer fila usando el\n",
    "# operador iloc (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)\n",
    "category_id = df.iloc[0]['id']\n",
    "\n",
    "# Dirección del servicio en la API REST\n",
    "url = \"https://api.mercadolibre.com/categories/\" + category_id\n",
    "\n",
    "# Invocación al método\n",
    "response = requests.get(url)\n",
    "\n",
    "# Obtengo el resultado de la respuesta como JSON\n",
    "content = response.json()\n",
    "\n",
    "print(json.dumps(content, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Fuentes-Datos-Abiertas'></a>\n",
    "## Fuentes de datos abiertas\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "Son uno de los insumos más ricos e importantes en ciencia de datos, y de las cuales podemos extraer muchisimo valor para agregar a nuestros análisis y aplicaciones. Desde un dataset de nombres de paises unificado, el mapa completo de paradas STM de Montevideo, hasta todas las colisiones de asteroides en la Tierra. Existen cientos de iniciativas que ponen a disposición datos y conocerlas es un paso importante en la carrera de todo científico de datos.\n",
    "\n",
    "A continaución vamos a ver algunos ejemplos:\n",
    "\n",
    "- **Datos abiertos estatales**: Son varios los paises que ponen a disposiciíon de la comunidad conjuntos de datos abiertos para su explotación y Uruguay no es la excepción!\n",
    "  - Catalogo datos abiertos Uruguay 🇺🇾 &rarr; https://catalogodatos.gub.uy/\n",
    "  - Datos abiertos Argentina 🇦🇷 &rarr; https://datos.gob.ar/\n",
    "  - Datos abiertos USA 🇺🇸 &rarr; https://www.data.gov/\n",
    "- **Kaggle**: Comunidad de data scientist dónde podrás encontrar data sets, corpus armados para algorítmos de AI, entre otros &rarr; https://www.kaggle.com/\n",
    "- **UCI**: Repositorio de data sets para Machine Learning &rarr; https://archive.ics.uci.edu/ml/index.php\n",
    "- **DBpedia**: Información de Wikipedia estructurada de forma semántica &rarr; https://wiki.dbpedia.org/\n",
    "- **Yelp**: Daots abiertos de la aplicación Yelp, Reviews de usuarios, Fotos, etc. &rarr; https://www.yelp.com/dataset\n",
    "- **Unicef**: Datos abiertos Unicef &rarr; https://data.unicef.org/resources/resource-type/datasets/\n",
    "- **NASA**: Catalogo de datos abiertos de la NASA &rarr; https://data.nasa.gov/\n",
    "\n",
    "**Yapa**\n",
    "\n",
    "[Google DataSets Search](https://toolbox.google.com/datasetsearch): Herramienta de Google, que busca datasets en la Web. En particular, indexa resultados de otras plataformas, como Kaggle, Datos Abiertos Estatales, etc.\n",
    "\n",
    "<img src=\"https://github.com/efviodo/data-science/raw/master/courses/utec/figures/google_datasearch.png\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Desafios'></a>\n",
    "## Desafíos\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "Existen ciertos desafíos que siempre estan presentes en la etapa de adquisición de datos, los principales son:\n",
    "\n",
    "- **Acceso a los datos**: Aveces los requerimientos estan pero el cliente demora en darnos acceso a sus datos.\n",
    "- **Formato de los datos**: Los datos están en un formato que no comprendemos o no entendemos.\n",
    "- **Problemas de encoding, escapeo de caracteres**: Que pasa si el encoding de un CSV no es UTF-8, si tiene columnas sin escapeo y algunos valores contienen el caracter separador. Aveces gastamos una cantidad considerable de tiempo pre-procesando los datos para poder ingerirlos y empezar la etapa de comprensión y análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué pasa si necesitamos generar datos?\n",
    "\n",
    "Aveces la fuente de datos del cliente, NO contiene todos los datos que necesitamos y tampoco encontramos un dataset abierto que tenga la información que necesitamos. En estos casos debemos generar nosotros mismos el dataset.\n",
    "\n",
    "**Ejemplo**\n",
    "Queremos armar un dataset con las asistencias de estudiantes en distintos centros de educación terciaria del páis, para luego analizar si hay alguna correlación entre las inasistencias y por ejemplo alguna otra variable como la ubicación del centro de estudios (Montevideo/Interior), la cercanía del estudiante al centro, la fecha del año, el clima, etc. \n",
    "\n",
    "En este caso, debemos preguntarnos:\n",
    "\n",
    "- ¿Que formato vamos a utilizar? ¿Arhivos CSV, TXT, una BD?\n",
    "- ¿Qué datos queremos incluír? Y para cada uno\n",
    "    - Qué tipo de datos vamos a utilizar para representar cada atributo, si vamos a usar codigeras...\n",
    "- ¿Cómo vamos a recuperar los datos?\n",
    "- ¿Cómo me aceguro que este dataset sea re-utilizable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Bibliografia'></a>\n",
    "## Bibliografía\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "<ol>\n",
    "    <li>Comparación entre Pandas Data Frame y R Data Frames <br />\n",
    "        <a href=\"https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html\">https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html</a>\n",
    "    </li>\n",
    "    <li>\n",
    "        Referencia Python Pandas\n",
    "        <br /><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/index.html\">https://pandas.pydata.org/pandas-docs/stable/reference/index.html</a>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
