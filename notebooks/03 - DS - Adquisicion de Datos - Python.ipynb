{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/efviodo/idatha-data-science-course/blob/master/notebooks/03%20-%20DS%20-%20Adquisicion%20de%20Datos%20-%20Python.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/efviodo/idatha-data-science-course/raw/master/notebooks/figures/idatha-logo.jpeg\" width=\"100px\" height=\"100px\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adquisici√≥n de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "- Entender que es la etapa de adquisici√≥n de datos\n",
    "- Familiarizarse con las fuentes de datos m√°s comunes\n",
    "- Introducir algunas facilidades en Python para adquisici√≥n de datos\n",
    "- Enumerar los principales desaf√≠os y riesgos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Indice'></a>\n",
    "## √çndice\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "1. [¬øQu√© es la adquisici√≥n de datos?](#Adquisicion-Datos)\n",
    "1. [Fuentes de Datos](#Fuentes-Datos)\n",
    "    1. [Definici√≥n](#Definicion)\n",
    "    1. [Tipos](#Tipos)\n",
    "1. [Herramientas](#Herramientas)\n",
    "    1. [Bases de Datos (BDs)](#Bases-Datos)\n",
    "    1. [Sitios Web](#Sitios-Web)\n",
    "    1. [Datos Abiertos](#Datos-Abiertos)\n",
    "    1. [APIs REST](#Rest-Apis)\n",
    "1. [Fuentes de Datos Abiertas](#Fuentes-Datos-Abiertas)\n",
    "1. [Desaf√≠os](#Desafios)\n",
    "1. [Bibliograf√≠a](#Bibliografia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Adquisicion-Datos'></a>\n",
    "## ¬øQu√© es la adquisici√≥n de datos?\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "La adquisici√≥n de datos o tambi√©n conocido como ingesta de datos, es el proceso de obtener o importar los datos\n",
    "que se pretenden analizar, desde su **fuente**, y almacenarlos temporal o permanentemente para su posterior an√°lisis.\n",
    "\n",
    "Como resultado de esta operaci√≥n, el cient√≠fico de datos tiene a su dispocici√≥n uno o varios set de datos en un formato comprendido y manejado por este (archivos CSV, resultado de consultas SQL, data frames, etc), listo para comenzar con el an√°lisis y el entendimiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Fuentes-Datos'></a>\n",
    "## Fuentes de Datos\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "<a id='Definicion'></a>\n",
    "### Definici√≥n\n",
    "La fuente de un dato, es el lugar donde se encuentra el dato, desde la perspectiva de quien dise√±a el proceso de an√°lisis. Por ejemplo, puede ser un sensor IoT (Internet de las Cosas) al cual puedo conectarme para leer informaci√≥n, Redes Sociales (Twtter, Facebook), un sistema [ERP](https://es.wikipedia.org/wiki/Sistema_de_planificaci%C3%B3n_de_recursos_empresariales), base de datos de un cliente, sistemas de almacenamiento legados, fuentes de datos abiertas, sitios web, etc.\n",
    "\n",
    "Cada vez son m√°s y m√°s los lugares donde se originan datos y a los cuales podemos acceder y explotar. Conforme crecen las fuentes de datos, tambi√©n crecen y se originan nuevas tecnolog√≠as para acceder a ellos.\n",
    "\n",
    "### Tipos\n",
    "Dependiendo de donde se encuentren los datos, como accederemos a ellos, es decir como nos conectamos y que tecnolog√≠a utilizamos. De esta forma, resulta √∫til agrupar las fuentes de datos en diferentes tipos:\n",
    "\n",
    "- Bases de datos de clientes: Relacionales/No Relacionales, archivos PDF, fotos (PNG, JPG...), Big Data, etc.\n",
    "- Sitios Web: T√©cnicas de web crawling y web scraping\n",
    "- Redes sociales: Integraci√≥n via APIs REST\n",
    "- Datos Abiertos: Carga de archivos con formato (CSV, TXT, PDF, etc), integraci√≥n mediante APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Herramientas'></a>\n",
    "## Herramientas\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "Cada lenguaje de programaci√≥n tiene su oferta de herramientas que facilitan la integraci√≥n con otros sistemas, y as√≠ la adquisici√≥n de datos. A continuaci√≥n se enumeran algunos ejemplos de herramientas que podr√°s encontrar en **Python**, y que te ayudaran en la adiquisici√≥n de datos. \n",
    "\n",
    "<a id='Bases-Datos'></a>\n",
    "### Bases de Datos (BDs)\n",
    "Dentro de **Python**, podemos encontrar variedad de librerias para acceder a distintos motores de base de datos, MySQL, Oracle, PostgreSQL, MongoDB, etc. Algunos ejemplos de librer√≠as para conectarse a bases de datos:\n",
    "\n",
    "* MongoDB &rarr; [PyMongo](https://pypi.org/project/pymongo/)\n",
    "* PostgreSQL &rarr; [Psycopg2](https://pypi.org/project/psycopg2/)\n",
    "* MySQL &rarr; [mysql-connector](https://www.w3schools.com/python/python_mysql_getstarted.asp)\n",
    "\n",
    "<a id='Sitios-Web'></a>\n",
    "### Sitios Web\n",
    "\n",
    "Es bastante com√∫n, la necesidad de extraer informaci√≥n de un sitio web y de a su vez de forma autom√°tica. Para ello existen dos t√©cnicas bien conocidas que son: (i) Web Scarping y (ii) Web Crawling.\n",
    "\n",
    "#### ¬øQu√© es web Scraping?\n",
    "Es el acto de procesar un documento web y extraer informaci√≥n del mismo. \n",
    "\n",
    "#### ¬øQu√© es web Crawling?\n",
    "Es el proceso de encontrar y recuperar \"web links\", desde una lista inicial de URLs, navegando el contenido de la lista inicial y aplicando t√©cnicas de web scraping para encontrar nuevos links.\n",
    "\n",
    "Existen varias herramientas que implementan estas t√©cnicas, una de las m√°s populares es la libreria de Python [Scrapy](https://scrapy.org/).\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "A continuaci√≥n vamos a ver un ejemplo de como extraer informaci√≥n del popular sitio web de rese√±as de peliculas, [IMDb](https://www.imdb.com). Para ello vamos a usar **Python** y las librerias [Requests](https://pypi.org/project/requests/) y [BeautifulSoup](https://pypi.org/project/beautifulsoup4/), para recuperar los primeros resultados de b√∫squeda de peliculas cuya fecha de lanzamiento se encuentra entre el a√±o 2018 y 2019.\n",
    "\n",
    "Si te sientes curioso, hacer el scrapping completo de un sitio web puede ser bastante m√°s complicado que esto, incluso si queremos navegar en paginas hijas y descargar un sitio completo. Para ello suelen utilizarse librer√≠as m√°s elaboradas como [Scrapy](https://docs.scrapy.org/en/latest/intro/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (2019.3.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/emiliano/.conda/envs/taller_cdatos2/lib/python3.7/site-packages (from requests) (1.24.3)\n",
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102kB 2.8MB/s a 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>=1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/42/d821581cf568e9b7dfc5b415aa61952b0f5e3dede4f3cbd650e3a1082992/soupsieve-1.9.4-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/emiliano/.cache/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.8.0 bs4-0.0.1 soupsieve-1.9.4\n"
     ]
    }
   ],
   "source": [
    "# Instalacion de librerias\n",
    "!pip install requests\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joker\n",
      "Ad Astra\n",
      "Rambo: Last Blood\n",
      "Downton Abbey\n",
      "Hustlers\n",
      "It Chapter Two\n",
      "Midsommar\n",
      "The Irishman\n",
      "Doom: Annihilation\n",
      "El Camino: A Breaking Bad Movie\n",
      "Once Upon a Time... in Hollywood\n",
      "Between Two Ferns: The Movie\n",
      "Spider-Man: Far from Home\n",
      "Fast & Furious Presents: Hobbs & Shaw\n",
      "Tall Girl\n",
      "Crawl\n",
      "Judy\n",
      "Aladdin\n",
      "In the Shadow of the Moon\n",
      "Anna\n",
      "Avengers: Endgame\n",
      "Uncut Gems\n",
      "Frozen II\n",
      "Dark Phoenix\n",
      "Star Wars: The Rise of Skywalker\n",
      "Yesterday\n",
      "John Wick: Chapter 3 - Parabellum\n",
      "Toy Story 4\n",
      "Three from Hell\n",
      "Abominable\n",
      "The Goldfinch\n",
      "Zombieland: Double Tap\n",
      "Ready or Not\n",
      "Terminator: Dark Fate\n",
      "Bohemian Rhapsody\n",
      "Running with the Devil\n",
      "Gemini Man\n",
      "Bloodline\n",
      "Rocketman\n",
      "Child's Play\n",
      "Gisaengchung\n",
      "Angel Has Fallen\n",
      "The Peanut Butter Falcon\n",
      "Annabelle Comes Home\n",
      "Maleficent: Mistress of Evil\n",
      "Charlie's Angels\n",
      "War\n",
      "The Lion King\n",
      "Knives Out\n",
      "Good Boys\n",
      "Men in Black: International\n",
      "Kabir Singh\n",
      "The Dead Don't Die\n",
      "Booksmart\n",
      "Godzilla: King of the Monsters\n",
      "The Lighthouse\n",
      "Haunt\n",
      "Alita: Battle Angel\n",
      "Ford v Ferrari\n",
      "Aquaman\n",
      "Robin Hood\n",
      "Inside Man: Most Wanted\n",
      "The Day Shall Come\n",
      "The Addams Family\n",
      "Doctor Sleep\n",
      "Lucy in the Sky\n",
      "Jojo Rabbit\n",
      "Hereditary\n",
      "Hotel Mumbai\n",
      "We Have Always Lived in the Castle\n",
      "Spider-Man: Into the Spider-Verse\n",
      "Scary Stories to Tell in the Dark\n",
      "The Aeronauts\n",
      "Brightburn\n",
      "Danger Close: The Battle of Long Tan\n",
      "Can You Keep a Secret?\n",
      "Dream Girl\n",
      "Welcome to Marwen\n",
      "Long Shot\n",
      "Shazam!\n",
      "Animales fant√°sticos: Los cr√≠menes de Grindelwald\n",
      "Jay and Silent Bob Reboot\n",
      "Last Christmas\n",
      "Avengers: Infinity War\n",
      "The Lego Movie 2: The Second Part\n",
      "Us\n",
      "Jumanji: The Next Level\n",
      "A Simple Favor\n",
      "Midway\n",
      "Green Book\n",
      "Wounds\n",
      "Captain Marvel\n",
      "The Secret Life of Pets 2\n",
      "The Laundromat\n",
      "Dora and the Lost City of Gold\n",
      "The Hustle\n",
      "Chhichhore\n",
      "Corporate Animals\n",
      "Mary Queen of Scots\n",
      "Dolor y gloria\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define URL a descargar y hace la petici√≥n HTTP\n",
    "url = 'http://www.imdb.com/search/title?count=100&release_date=2018,2019&title_type=feature'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Crea objeto BeautifulSoup para procesar HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Obtengo todos los elementos H3 con clase de estilos lister-item-header (yo se que all√≠ estan los t√≠tulos)\n",
    "elements = soup.findAll('h3', {'class': 'lister-item-header'})\n",
    "\n",
    "# El resultado es una lista, itero para cada uno\n",
    "for element in elements:\n",
    "    # El titulo est√° dentro de un link\n",
    "    title = element.find(\"a\", recursive=False).next\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar, la comlejidad que implica hacer web scarping para un data scientist\n",
    "- Necesitamos conocer la estructura de la p√°gina web.\n",
    "- Conocer las b√°sicas de HTML, CSS, entre otros.\n",
    "- Si la estructura de la p√°gina cambia, necesito cambiar el programa que hace scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Datos-Abiertos'></a>\n",
    "### Datos abiertos\n",
    "Los datos abiertos suelen encontrarse en diferentes formatos, pero los principales son: CSV, XML, JSON, TXT y PDF. A su vez, dependiendo de la naturaleza del dato, puede que encuentres otros formatos como PNG (usualmente en datasets de imagenes en el √°rea Computer Vision) o Shapefile (datos espaciales).\n",
    "\n",
    "Afortunadamente, existen librerias que implementan el acceso a estos formatos de archivos y manejan toda la complejidad de leerlos y extraer la informaci√≥n que necesitamos.\n",
    "\n",
    "Para fijar ideas, vamos a ver como descargar un archivo CSV de datos, cargarlo y recuperar un poco de informaci√≥n del mismo. Para ello vamos a usar nuevamente la liber√≠a [Requests](https://pypi.org/project/requests/) las librerias y adem√°s utilizaremos la libref√≠a [Pandas](https://pandas.pydata.org/) para facilitar la carga de los datos como una tabla y manipularlos mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101220.0</td>\n",
       "      <td>101353.0</td>\n",
       "      <td>101453.0</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102053.0</td>\n",
       "      <td>102577.0</td>\n",
       "      <td>103187.0</td>\n",
       "      <td>103795.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>8996351.0</td>\n",
       "      <td>9166764.0</td>\n",
       "      <td>9345868.0</td>\n",
       "      <td>9533954.0</td>\n",
       "      <td>9731361.0</td>\n",
       "      <td>9938414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26616792.0</td>\n",
       "      <td>27294031.0</td>\n",
       "      <td>28004331.0</td>\n",
       "      <td>28803167.0</td>\n",
       "      <td>29708599.0</td>\n",
       "      <td>30696958.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>32758020.0</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>34656032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>5643182.0</td>\n",
       "      <td>5753024.0</td>\n",
       "      <td>5866061.0</td>\n",
       "      <td>5980417.0</td>\n",
       "      <td>6093321.0</td>\n",
       "      <td>6203299.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20997687.0</td>\n",
       "      <td>21759420.0</td>\n",
       "      <td>22549547.0</td>\n",
       "      <td>23369131.0</td>\n",
       "      <td>24218565.0</td>\n",
       "      <td>25096150.0</td>\n",
       "      <td>25998340.0</td>\n",
       "      <td>26920466.0</td>\n",
       "      <td>27859305.0</td>\n",
       "      <td>28813463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2970017.0</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82683.0</td>\n",
       "      <td>83861.0</td>\n",
       "      <td>84462.0</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83751.0</td>\n",
       "      <td>82431.0</td>\n",
       "      <td>80788.0</td>\n",
       "      <td>79223.0</td>\n",
       "      <td>78014.0</td>\n",
       "      <td>77281.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code     Indicator Name Indicator Code       1960  \\\n",
       "0        Aruba          ABW  Population, total    SP.POP.TOTL    54211.0   \n",
       "1  Afghanistan          AFG  Population, total    SP.POP.TOTL  8996351.0   \n",
       "2       Angola          AGO  Population, total    SP.POP.TOTL  5643182.0   \n",
       "3      Albania          ALB  Population, total    SP.POP.TOTL  1608800.0   \n",
       "4      Andorra          AND  Population, total    SP.POP.TOTL    13411.0   \n",
       "\n",
       "        1961       1962       1963       1964       1965  ...        2007  \\\n",
       "0    55438.0    56225.0    56695.0    57032.0    57360.0  ...    101220.0   \n",
       "1  9166764.0  9345868.0  9533954.0  9731361.0  9938414.0  ...  26616792.0   \n",
       "2  5753024.0  5866061.0  5980417.0  6093321.0  6203299.0  ...  20997687.0   \n",
       "3  1659800.0  1711319.0  1762621.0  1814135.0  1864791.0  ...   2970017.0   \n",
       "4    14375.0    15370.0    16412.0    17469.0    18549.0  ...     82683.0   \n",
       "\n",
       "         2008        2009        2010        2011        2012        2013  \\\n",
       "0    101353.0    101453.0    101669.0    102053.0    102577.0    103187.0   \n",
       "1  27294031.0  28004331.0  28803167.0  29708599.0  30696958.0  31731688.0   \n",
       "2  21759420.0  22549547.0  23369131.0  24218565.0  25096150.0  25998340.0   \n",
       "3   2947314.0   2927519.0   2913021.0   2905195.0   2900401.0   2895092.0   \n",
       "4     83861.0     84462.0     84449.0     83751.0     82431.0     80788.0   \n",
       "\n",
       "         2014        2015        2016  \n",
       "0    103795.0    104341.0    104822.0  \n",
       "1  32758020.0  33736494.0  34656032.0  \n",
       "2  26920466.0  27859305.0  28813463.0  \n",
       "3   2889104.0   2880703.0   2876101.0  \n",
       "4     79223.0     78014.0     77281.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://github.com/efviodo/idatha-data-science-course/raw/master/notebooks/datasets/world-bank-data/country_population.csv\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = requests.get(url).content\n",
    "\n",
    "df = pd.read_csv(io.StringIO(data.decode('utf-8')))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, acabamos de leer los datos de senso de poblaci√≥n de diferentes pa√≠ses para distintos a√±os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 61)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Puedo analizar las dimensiones del dataset como cantidad de columnas o filas de datos.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
       "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
       "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
       "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
       "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
       "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
       "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
       "       '2014', '2015', '2016'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver que columnas tiene nuestro data frame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>104822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>34656032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>28813463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2876101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>77281.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name        2016\n",
       "0        Aruba    104822.0\n",
       "1  Afghanistan  34656032.0\n",
       "2       Angola  28813463.0\n",
       "3      Albania   2876101.0\n",
       "4      Andorra     77281.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecciona solamente las columnas Nombre de Pais y poblaci√≥n en el a√±o 2016\n",
    "df2 = df[['Country Name', '2016']];\n",
    "\n",
    "# Ordena de forma ascendente (para ordenar de forma descendente usar desc())\n",
    "df2.sort_values(by=['2016'])\n",
    "\n",
    "# Obtiene primeros 5 resultados\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python tiene una gran variedad de librer√≠as para trabajar con datos. En particulr la librer√≠a pandas es bastante utilizada por su uso eficiente de memoria y optimizaciones sobre matrices utilizando [numpy](https://numpy.org/) para operaciones. M√°s adelante en este taller vamos a ir viendo m√°s ejemplos de operaciones y transformaciones utilizando Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Rest-Apis'></a>\n",
    "### APIs REST\n",
    "Muchas veces en un proyecto de ciencia de datos, tenemos el requerimiento de acceder a los datos a trav√©s de una API REST. Naturalmente no vamos a re-implementar la rueda y desarrollar un programa que establezca una conexi√≥n HTTP, parse la respuesta, etc. Existen librerias que implementan clientes rest y tambi√©n librer√≠as que nos ayudan a parsear respuestas en formato JSON, XML, etc. Veamos un ejemplo en el que utilizamos las librerias ```httr``` y ```jsonlite``` para invocar la API de la popular plataforma de compra venta de bienes y servicios [Mercado Libre](https://developers.mercadolibre.com.uy/es_ar). En el mismo, vamos a recuperar y mostrar informaci√≥n de las categor√≠as de productos que se ofrecen a trav√©s de la plataforma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consumiendo servicio REST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importo librerias \n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Direcci√≥n del servicio en la API REST\n",
    "url = \"https://api.mercadolibre.com/sites/MLU\"\n",
    "\n",
    "# Invocaci√≥n al m√©todo\n",
    "response = requests.get(url)\n",
    "\n",
    "# Obtenemos el status code de la respuesta con el operador '$'\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parseando contenido de la respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLU5725</td>\n",
       "      <td>Accesorios para Veh√≠culos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLU1403</td>\n",
       "      <td>Alimentos y Bebidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLU1071</td>\n",
       "      <td>Animales y Mascotas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLU1367</td>\n",
       "      <td>Arte y Antig√ºedades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLU1743</td>\n",
       "      <td>Autos, Motos y Otros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       name\n",
       "0  MLU5725  Accesorios para Veh√≠culos\n",
       "1  MLU1403        Alimentos y Bebidas\n",
       "2  MLU1071        Animales y Mascotas\n",
       "3  MLU1367        Arte y Antig√ºedades\n",
       "4  MLU1743       Autos, Motos y Otros"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraigo el contenido de la respuesta como JSON\n",
    "content = response.json()\n",
    "\n",
    "# El resultado tiene varios atributos, me quedo solo con el atributo categorias\n",
    "categories = content['categories']\n",
    "\n",
    "# Construyo un data frame a partir del la lista de categorias\n",
    "df = pd.DataFrame.from_dict(categories)\n",
    "\n",
    "# Veamos el resultado\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parseando como JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"MLU5725\",\n",
      "    \"name\": \"Accesorios para Veh\\u00edculos\",\n",
      "    \"picture\": \"http://resources.mlstatic.com/category/images/a0572646-bbf9-4b24-81c8-603723a015ba.png\",\n",
      "    \"permalink\": \"http://home.mercadolibre.com.uy/vehiculos-accesorios/\",\n",
      "    \"total_items_in_this_category\": 456475,\n",
      "    \"path_from_root\": [\n",
      "        {\n",
      "            \"id\": \"MLU5725\",\n",
      "            \"name\": \"Accesorios para Veh\\u00edculos\"\n",
      "        }\n",
      "    ],\n",
      "    \"children_categories\": [\n",
      "        {\n",
      "            \"id\": \"MLU417044\",\n",
      "            \"name\": \"Acc. y Repuestos N\\u00e1uticos\",\n",
      "            \"total_items_in_this_category\": 68\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1747\",\n",
      "            \"name\": \"Accesorios Autos y Camionetas\",\n",
      "            \"total_items_in_this_category\": 70470\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1772\",\n",
      "            \"name\": \"Accesorios para Motos\",\n",
      "            \"total_items_in_this_category\": 23218\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1023\",\n",
      "            \"name\": \"Audio para Autos\",\n",
      "            \"total_items_in_this_category\": 11543\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU208681\",\n",
      "            \"name\": \"Llantas\",\n",
      "            \"total_items_in_this_category\": 4843\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU208675\",\n",
      "            \"name\": \"Neum\\u00e1ticos\",\n",
      "            \"total_items_in_this_category\": 15859\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1748\",\n",
      "            \"name\": \"Repuestos Autos y Camionetas\",\n",
      "            \"total_items_in_this_category\": 270442\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU1771\",\n",
      "            \"name\": \"Repuestos para Motos\",\n",
      "            \"total_items_in_this_category\": 29976\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU206455\",\n",
      "            \"name\": \"Service Programado\",\n",
      "            \"total_items_in_this_category\": 2527\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU5679\",\n",
      "            \"name\": \"Tuning\",\n",
      "            \"total_items_in_this_category\": 20745\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"MLU6177\",\n",
      "            \"name\": \"Otros\",\n",
      "            \"total_items_in_this_category\": 6795\n",
      "        }\n",
      "    ],\n",
      "    \"attribute_types\": \"none\",\n",
      "    \"settings\": {\n",
      "        \"adult_content\": false,\n",
      "        \"buying_allowed\": true,\n",
      "        \"buying_modes\": [\n",
      "            \"buy_it_now\",\n",
      "            \"auction\"\n",
      "        ],\n",
      "        \"catalog_domain\": null,\n",
      "        \"coverage_areas\": \"not_allowed\",\n",
      "        \"currencies\": [\n",
      "            \"UYU\",\n",
      "            \"USD\"\n",
      "        ],\n",
      "        \"fragile\": false,\n",
      "        \"immediate_payment\": \"optional\",\n",
      "        \"item_conditions\": [\n",
      "            \"used\",\n",
      "            \"not_specified\",\n",
      "            \"new\"\n",
      "        ],\n",
      "        \"items_reviews_allowed\": false,\n",
      "        \"listing_allowed\": false,\n",
      "        \"max_description_length\": 50000,\n",
      "        \"max_pictures_per_item\": 12,\n",
      "        \"max_pictures_per_item_var\": 10,\n",
      "        \"max_sub_title_length\": 70,\n",
      "        \"max_title_length\": 60,\n",
      "        \"maximum_price\": null,\n",
      "        \"minimum_price\": null,\n",
      "        \"mirror_category\": null,\n",
      "        \"mirror_master_category\": null,\n",
      "        \"mirror_slave_categories\": [],\n",
      "        \"price\": \"required\",\n",
      "        \"reservation_allowed\": \"not_allowed\",\n",
      "        \"restrictions\": [],\n",
      "        \"rounded_address\": false,\n",
      "        \"seller_contact\": \"not_allowed\",\n",
      "        \"shipping_modes\": [\n",
      "            \"not_specified\",\n",
      "            \"custom\"\n",
      "        ],\n",
      "        \"shipping_options\": [\n",
      "            \"carrier\",\n",
      "            \"custom\"\n",
      "        ],\n",
      "        \"shipping_profile\": \"optional\",\n",
      "        \"show_contact_information\": false,\n",
      "        \"simple_shipping\": \"optional\",\n",
      "        \"stock\": \"required\",\n",
      "        \"sub_vertical\": null,\n",
      "        \"subscribable\": false,\n",
      "        \"tags\": [],\n",
      "        \"vertical\": null,\n",
      "        \"vip_subdomain\": \"articulo\",\n",
      "        \"buyer_protection_programs\": [\n",
      "            \"delivered\",\n",
      "            \"undelivered\"\n",
      "        ]\n",
      "    },\n",
      "    \"meta_categ_id\": null,\n",
      "    \"attributable\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Obtengo el identificador de la categoria en el resultado, para ello selecciona la primer fila usando el\n",
    "# operador iloc (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)\n",
    "category_id = df.iloc[0]['id']\n",
    "\n",
    "# Direcci√≥n del servicio en la API REST\n",
    "url = \"https://api.mercadolibre.com/categories/\" + category_id\n",
    "\n",
    "# Invocaci√≥n al m√©todo\n",
    "response = requests.get(url)\n",
    "\n",
    "# Obtengo el resultado de la respuesta como JSON\n",
    "content = response.json()\n",
    "\n",
    "print(json.dumps(content, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Fuentes-Datos-Abiertas'></a>\n",
    "## Fuentes de datos abiertas\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "Son uno de los insumos m√°s ricos e importantes en ciencia de datos, y de las cuales podemos extraer muchisimo valor para agregar a nuestros an√°lisis y aplicaciones. Desde un dataset de nombres de paises unificado, el mapa completo de paradas STM de Montevideo, hasta todas las colisiones de asteroides en la Tierra. Existen cientos de iniciativas que ponen a disposici√≥n datos y conocerlas es un paso importante en la carrera de todo cient√≠fico de datos.\n",
    "\n",
    "A continauci√≥n vamos a ver algunos ejemplos:\n",
    "\n",
    "- **Datos abiertos estatales**: Son varios los paises que ponen a disposici√≠on de la comunidad conjuntos de datos abiertos para su explotaci√≥n y Uruguay no es la excepci√≥n!\n",
    "  - Catalogo datos abiertos Uruguay üá∫üáæ &rarr; https://catalogodatos.gub.uy/\n",
    "  - Datos abiertos Argentina üá¶üá∑ &rarr; https://datos.gob.ar/\n",
    "  - Datos abiertos USA üá∫üá∏ &rarr; https://www.data.gov/\n",
    "- **Kaggle**: Comunidad de data scientist d√≥nde podr√°s encontrar data sets, corpus armados para algor√≠tmos de AI, entre otros &rarr; https://www.kaggle.com/\n",
    "- **UCI**: Repositorio de data sets para Machine Learning &rarr; https://archive.ics.uci.edu/ml/index.php\n",
    "- **DBpedia**: Informaci√≥n de Wikipedia estructurada de forma sem√°ntica &rarr; https://wiki.dbpedia.org/\n",
    "- **Yelp**: Daots abiertos de la aplicaci√≥n Yelp, Reviews de usuarios, Fotos, etc. &rarr; https://www.yelp.com/dataset\n",
    "- **Unicef**: Datos abiertos Unicef &rarr; https://data.unicef.org/resources/resource-type/datasets/\n",
    "- **NASA**: Catalogo de datos abiertos de la NASA &rarr; https://data.nasa.gov/\n",
    "\n",
    "**Yapa**\n",
    "\n",
    "[Google DataSets Search](https://toolbox.google.com/datasetsearch): Herramienta de Google, que busca datasets en la Web. En particular, indexa resultados de otras plataformas, como Kaggle, Datos Abiertos Estatales, etc.\n",
    "\n",
    "<img src=\"https://github.com/efviodo/data-science/raw/master/courses/utec/figures/google_datasearch.png\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Desafios'></a>\n",
    "## Desaf√≠os\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "Existen ciertos desaf√≠os que siempre estan presentes en la etapa de adquisici√≥n de datos, los principales son:\n",
    "\n",
    "- **Acceso a los datos**: Aveces los requerimientos estan pero el cliente demora en darnos acceso a sus datos.\n",
    "- **Formato de los datos**: Los datos est√°n en un formato que no comprendemos o no entendemos.\n",
    "- **Problemas de encoding, escapeo de caracteres**: Que pasa si el encoding de un CSV no es UTF-8, si tiene columnas sin escapeo y algunos valores contienen el caracter separador. Aveces gastamos una cantidad considerable de tiempo pre-procesando los datos para poder ingerirlos y empezar la etapa de comprensi√≥n y an√°lisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© pasa si necesitamos generar datos?\n",
    "\n",
    "Aveces la fuente de datos del cliente, NO contiene todos los datos que necesitamos y tampoco encontramos un dataset abierto que tenga la informaci√≥n que necesitamos. En estos casos debemos generar nosotros mismos el dataset.\n",
    "\n",
    "**Ejemplo**\n",
    "Queremos armar un dataset con las asistencias de estudiantes en distintos centros de educaci√≥n terciaria del p√°is, para luego analizar si hay alguna correlaci√≥n entre las inasistencias y por ejemplo alguna otra variable como la ubicaci√≥n del centro de estudios (Montevideo/Interior), la cercan√≠a del estudiante al centro, la fecha del a√±o, el clima, etc. \n",
    "\n",
    "En este caso, debemos preguntarnos:\n",
    "\n",
    "- ¬øQue formato vamos a utilizar? ¬øArhivos CSV, TXT, una BD?\n",
    "- ¬øQu√© datos queremos inclu√≠r? Y para cada uno\n",
    "    - Qu√© tipo de datos vamos a utilizar para representar cada atributo, si vamos a usar codigeras...\n",
    "- ¬øC√≥mo vamos a recuperar los datos?\n",
    "- ¬øC√≥mo me aceguro que este dataset sea re-utilizable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Bibliografia'></a>\n",
    "## Bibliograf√≠a\n",
    "[Inicio ‚ñ≤](#Indice)\n",
    "\n",
    "<ol>\n",
    "    <li>Comparaci√≥n entre Pandas Data Frame y R Data Frames <br />\n",
    "        <a href=\"https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html\">https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html</a>\n",
    "    </li>\n",
    "    <li>\n",
    "        Referencia Python Pandas\n",
    "        <br /><a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/index.html\">https://pandas.pydata.org/pandas-docs/stable/reference/index.html</a>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
